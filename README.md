
# Дополнения к анализу: тестирование распределения и стек технологий

---

## Тестирование распределения данных

### 1. Для регрессии (линейная модель)
- **Нормальность остатков**: 
  - Тест Шапиро-Уилка (`scipy.stats.shapiro`).
  - Визуализация: Q-Q plot остатков (использован `matplotlib`).
 

### 2. Для классификации ценового сегмента (Random Forest)
- **Балансировка классов**:
  - Анализ распределения через `value_counts()`.
  - Стратифицированное разбиение данных (`train_test_split()`).
  - Визуализация: Столбчатая диаграмма распределения классов (`seaborn.countplot`).

### 3. Для классификации брендов в Китае (SVM)
- **Мультиколлинеарность**:
  - Расчет корреляционной матрицы (`pandas.corr()`).
  - Удаление коррелирующих признаков на основе порога (например, `corr_threshold = 0.8`).

---

## Стек технологий

### Язык и окружение
- **Язык**: Python 3.10+
- **Инструменты**:
  - Jupyter Notebook — для исследования и анализа.
  - Git — контроль версий кода.

### Библиотеки
1. **Предобработка**:
   - `pandas` — загрузка данных и манипуляции с таблицами.
   - `numpy` — операции с массивами.
   - `scikit-learn`: 
     - `SimpleImputer` (заполнение пропусков),
     - `OneHotEncoder` (кодирование категориальных признаков),
     - `StandardScaler` (нормализация данных).

2. **Модели**:
   - **Регрессия**: `LinearRegression` (базовая модель).
   - **Классификация**:
     - `RandomForestClassifier` (ценовые сегменты),
     - `SVC` (SVM с ядром RBF для классификации брендов),
     - `KNeighborsClassifier` (тестирование KNN).

3. **Оптимизация**:
   - `GridSearchCV` — подбор гиперпараметров для SVM и Random Forest.

4. **Визуализация**:
   - `matplotlib` — базовые графики (распределения, остатки).
   - `seaborn` — тепловые карты корреляций, boxplot цен по странам.

5. **Статистика**:
   - `scipy.stats` — тест Шапиро-Уилка, анализ распределений.

### Инфраструктура
- **Хранение данных**: 
  - Реляционная база данных (MySQL) на персональном сервере.
  - Экспорт результатов в CSV для анализа.
- **Деплой**: Не реализован (анализ ограничен исследовательской частью).

---

## Обоснование выбора моделей

### 1. Линейная регрессия (цена)
- **Плюсы**: Прозрачность коэффициентов, быстрая интерпретация влияния RAM/процессора на цену.
- **Минусы**: Низкая точность при нелинейных зависимостях (использована как baseline).

### 2. Random Forest (ценовые сегменты)
- **Плюсы**:
  - Устойчивость к переобучению за счет агрегации деревьев.
  - Учет нелинейных взаимодействий (например, процессор + год выпуска).
- **Настройки**: `n_estimators=150`, `max_depth=12`.

### 3. DescisionTree (бренды в Китае)
- **Плюсы**:
  - Эффективная работа с разреженными данными после one-hot encoding.
  - Высокая точность на небольших выборках благодаря ядру RBF.
- **Настройки**: `C=1.0`, `gamma='scale'`.

---

## Пример кода (анализ корреляций)
```python
# Построение тепловой карты корреляций
import seaborn as sns
import matplotlib.pyplot as plt

corr_matrix = df.corr()
plt.figure(figsize=(12, 8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title("Корреляция между признаками")
plt.show()